import streamlit as st
import feedparser
import google.generativeai as genai
from github_db import GithubDB
from datetime import datetime
import time

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
st.set_page_config(page_title="ë‚˜ë§Œì˜ ê¸ˆìœµ ë‰´ìŠ¤ë£¸", layout="wide", page_icon="ğŸ“ˆ")

# Streamlit Secretsì—ì„œ í‚¤ ê°€ì ¸ì˜¤ê¸°
try:
    USE_LOCAL = st.secrets.get("USE_LOCAL", False)  # ë¡œì»¬ ê°œë°œ ëª¨ë“œ (ê¸°ë³¸ê°’: False)
    GITHUB_TOKEN = st.secrets.get("GITHUB_TOKEN", "")
    REPO_NAME = st.secrets.get("REPO_NAME", "")
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError as e:
    st.error(f"Secrets ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤: {e}. (.streamlit/secrets.toml í™•ì¸)")
    st.stop()
except Exception as e:
    st.error(f"Secrets ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

# ë¡œì»¬ ëª¨ë“œ ì²´í¬
if USE_LOCAL:
    st.warning("âš ï¸ ë¡œì»¬ ê°œë°œ ëª¨ë“œ: GitHub ì—°ê²° ì—†ì´ ë¡œì»¬ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    db = GithubDB("", "", use_local=True)
else:
    if not GITHUB_TOKEN or not REPO_NAME:
        st.error("GitHub í† í°ê³¼ ë¦¬í¬ì§€í† ë¦¬ ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.info("ğŸ’¡ ë¡œì»¬ ê°œë°œ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ secrets.tomlì— USE_LOCAL = trueë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        st.stop()
    
    # DB ë° AI ì´ˆê¸°í™”
    try:
        db = GithubDB(GITHUB_TOKEN, REPO_NAME)
    except Exception as e:
        st.error(f"GitHub ì—°ê²° ì‹¤íŒ¨: {e}")
        st.info("ğŸ’¡ ë¡œì»¬ ê°œë°œ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ secrets.tomlì— USE_LOCAL = trueë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        st.stop()

# AI ì´ˆê¸°í™”
try:
    genai.configure(api_key=GEMINI_API_KEY)
except Exception as e:
    st.error(f"Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    st.stop()

# --- í—¬í¼ í•¨ìˆ˜ ---
def fetch_news(feeds, keywords):
    """RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° í‚¤ì›Œë“œ í•„í„°ë§"""
    articles = []
    for url in feeds:
        try:
            feed = feedparser.parse(url)
            if feed.bozo:  # íŒŒì‹± ì˜¤ë¥˜ ì²´í¬
                st.warning(f"í”¼ë“œ íŒŒì‹± ì˜¤ë¥˜: {url}")
                continue
                
            for entry in feed.entries:
                # ë‚ ì§œ íŒŒì‹± (ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ í•„í„°ë§ì„ ì›í•˜ë©´ ì—¬ê¸°ì„œ ë¡œì§ ì¶”ê°€)
                text_content = f"{entry.title} {entry.get('summary', '')}"
                
                # í‚¤ì›Œë“œê°€ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ìˆ˜ì§‘ (í‚¤ì›Œë“œê°€ ë¹„ì–´ìˆìœ¼ë©´ ëª¨ë‘ ìˆ˜ì§‘)
                if not keywords or any(k in text_content for k in keywords):
                    articles.append({
                        "title": entry.title,
                        "link": entry.link,
                        "published": entry.get("published", str(datetime.now())),
                        "summary": entry.get("summary", "")
                    })
        except Exception as e:
            st.warning(f"í”¼ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨ ({url}): {e}")
            continue
    return articles[:30]  # ë„ˆë¬´ ë§ìœ¼ë©´ í† í° ì œí•œ ê±¸ë¦¬ë¯€ë¡œ ìƒìœ„ 30ê°œë§Œ

def analyze_with_gemini(articles):
    """Geminië¥¼ ì´ìš©í•´ 1ì¥ì§œë¦¬ ë¸Œë¦¬í•‘ ì‘ì„±"""
    if not articles:
        return "ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    news_text = ""
    for idx, art in enumerate(articles):
        news_text += f"{idx+1}. {art['title']}\n"
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ
    'ì˜¤ëŠ˜ì˜ ê¸ˆìœµ ì‹œì¥ ì¼ì¼ ë¸Œë¦¬í•‘' ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [ìš”êµ¬ì‚¬í•­]
    1. ì „ì²´ì ì¸ ì‹œì¥ ë¶„ìœ„ê¸°ë¥¼ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
    2. ê°€ì¥ ì¤‘ìš”í•œ ì´ìŠˆ 3ê°€ì§€ë¥¼ ì„ ì •í•˜ì—¬ ì‹¬ì¸µ ë¶„ì„í•˜ì„¸ìš”.
    3. íˆ¬ììì—ê²Œ ì£¼ëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ 'Bull'ê³¼ 'Bear' ê´€ì ì—ì„œ ì •ë¦¬í•˜ì„¸ìš”.
    4. ì¶œë ¥ í˜•ì‹ì€ Markdownìœ¼ë¡œ ê°€ë…ì„± ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
    
    [ë‰´ìŠ¤ ë°ì´í„°]
    {news_text}
    """
    
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return f"âš ï¸ AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# --- ì•± ë¡œì§ ì‹œì‘ ---

# ë°ì´í„° ë¡œë“œ (ì´ˆê¸° ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒì„±)
default_data = {
    "feeds": [
        "https://news.google.com/rss/search?q=finance&hl=ko&gl=KR&ceid=KR:ko"
    ],
    "keywords": ["ì£¼ì‹", "ê¸ˆë¦¬", "ì‚¼ì„±ì „ì"],
    "visitors": 0,
    "reports": {},
    "collected_news": {}  # ë‚ ì§œë³„ë¡œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ì €ì¥
}
data = db.read_data(default_data=default_data)
if not data:
    st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    st.stop()

# ë°©ë¬¸ì ìˆ˜ ì¦ê°€ (ë” ì•ˆì „í•œ ë°©ì‹ - ìµœì‹  ë°ì´í„° ë‹¤ì‹œ ì½ê¸°)
if 'visited' not in st.session_state:
    # ìµœì‹  ë°ì´í„° ë‹¤ì‹œ ì½ê¸°
    current_data = db.read_data()
    if current_data:
        current_data['visitors'] = current_data.get('visitors', 0) + 1
        if db.write_data(current_data, "Increment visitor count"):
            data = current_data
            st.session_state['visited'] = True
        else:
            st.warning("ë°©ë¬¸ì ìˆ˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")

# --- UI êµ¬ì„± ---
st.title("ğŸ“ˆ AI Financial Newsroom")
st.markdown(f"**Total Visitors:** {data['visitors']}")

tab1, tab2, tab3 = st.tabs(["ğŸ“… ë°ì¼ë¦¬ ë¸Œë¦¬í•‘", "ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤", "âš™ï¸ ëŒ€ì‹œë³´ë“œ & ì„¤ì •"])

# [íƒ­ 1] ë©”ì¸: ë‚ ì§œë³„ ë¸Œë¦¬í•‘
with tab1:
    today_str = datetime.now().strftime("%Y-%m-%d")
    
    # ì €ì¥ëœ ë¦¬í¬íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
    if today_str in data['reports']:
        st.success(f"âœ… {today_str} ë¸Œë¦¬í•‘ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.markdown(data['reports'][today_str]['content'])
        
        with st.expander("ì°¸ê³ í•œ ì›ë³¸ ê¸°ì‚¬ ëª©ë¡"):
            for art in data['reports'][today_str]['sources']:
                st.write(f"- [{art['title']}]({art['link']})")
    else:
        st.info(f"ì•„ì§ {today_str} ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹œë³´ë“œì—ì„œ ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

# [íƒ­ 2] ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë³´ê¸° (ê°„ë‹¨í•œ ëª©ë¡)
with tab2:
    today_str = datetime.now().strftime("%Y-%m-%d")
    
    # ì˜¤ëŠ˜ ë‚ ì§œì˜ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ í‘œì‹œ
    collected_news = data.get('collected_news', {})
    date_keys = [k for k in collected_news.keys() if not k.endswith('_collected_at')]
    
    if today_str in date_keys:
        articles = collected_news[today_str]
        st.success(f"âœ… ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ {len(articles)}ê°œ")
        
        # ì œëª©ê³¼ ë§í¬ë§Œ ê°„ë‹¨í•˜ê²Œ í‘œì‹œ
        for idx, art in enumerate(articles, 1):
            st.write(f"{idx}. [{art['title']}]({art['link']})")
    else:
        st.info("ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹œë³´ë“œì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")

# [íƒ­ 3] ëŒ€ì‹œë³´ë“œ: ì„¤ì • ë° ìˆ˜ë™ ì‹¤í–‰
with tab3:
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“¡ RSS í”¼ë“œ ê´€ë¦¬")
        new_feed = st.text_input("RSS URL ì¶”ê°€")
        if st.button("í”¼ë“œ ì¶”ê°€"):
            if new_feed and new_feed not in data['feeds']:
                # URL ê²€ì¦ (ê°„ë‹¨í•œ ê²€ì¦)
                if new_feed.startswith(('http://', 'https://')):
                    # ìµœì‹  ë°ì´í„° ë‹¤ì‹œ ì½ê¸°
                    current_data = db.read_data()
                    if current_data:
                        current_data['feeds'].append(new_feed)
                        if db.write_data(current_data, "Add RSS feed"):
                            st.success("í”¼ë“œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.rerun()
                        else:
                            st.error("í”¼ë“œ ì¶”ê°€ ì‹¤íŒ¨")
                    else:
                        st.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                else:
                    st.warning("ìœ íš¨í•œ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš” (http:// ë˜ëŠ” https://ë¡œ ì‹œì‘)")
        
        st.write("í˜„ì¬ ë“±ë¡ëœ í”¼ë“œ:")
        for f in data['feeds']:
            c1, c2 = st.columns([8, 2])
            c1.text(f)
            if c2.button("ì‚­ì œ", key=f):
                # ìµœì‹  ë°ì´í„° ë‹¤ì‹œ ì½ê¸°
                current_data = db.read_data()
                if current_data and f in current_data['feeds']:
                    current_data['feeds'].remove(f)
                    if db.write_data(current_data, "Remove RSS feed"):
                        st.success("í”¼ë“œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
                    else:
                        st.error("í”¼ë“œ ì‚­ì œ ì‹¤íŒ¨")

    with col2:
        st.subheader("ğŸ” ê´€ì‹¬ í‚¤ì›Œë“œ")
        new_keyword = st.text_input("í‚¤ì›Œë“œ ì¶”ê°€ (ì˜ˆ: ë°˜ë„ì²´)")
        if st.button("í‚¤ì›Œë“œ ì¶”ê°€"):
            if new_keyword and new_keyword.strip() and new_keyword not in data['keywords']:
                # ìµœì‹  ë°ì´í„° ë‹¤ì‹œ ì½ê¸°
                current_data = db.read_data()
                if current_data:
                    current_data['keywords'].append(new_keyword.strip())
                    if db.write_data(current_data, "Add keyword"):
                        st.success("í‚¤ì›Œë“œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
                    else:
                        st.error("í‚¤ì›Œë“œ ì¶”ê°€ ì‹¤íŒ¨")
                else:
                    st.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        
        st.write("í˜„ì¬ ë“±ë¡ëœ í‚¤ì›Œë“œ:")
        for kw in data['keywords']:
            k1, k2 = st.columns([8, 2])
            k1.write(f"â€¢ {kw}")
            if k2.button("ì‚­ì œ", key=f"del_kw_{kw}"):
                # ìµœì‹  ë°ì´í„° ë‹¤ì‹œ ì½ê¸°
                current_data = db.read_data()
                if current_data and kw in current_data['keywords']:
                    current_data['keywords'].remove(kw)
                    if db.write_data(current_data, "Remove keyword"):
                        st.success("í‚¤ì›Œë“œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
                    else:
                        st.error("í‚¤ì›Œë“œ ì‚­ì œ ì‹¤íŒ¨")
        
        st.divider()
        st.subheader("ğŸ“¥ ë‰´ìŠ¤ ìˆ˜ì§‘")
        if st.button("ë‰´ìŠ¤ ìˆ˜ì§‘ (ì§€ê¸ˆ ì‹¤í–‰)", type="primary"):
            with st.spinner("RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
                # ë‰´ìŠ¤ ìˆ˜ì§‘
                articles = fetch_news(data['feeds'], data['keywords'])
                
                if not articles:
                    st.warning("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. RSS í”¼ë“œë‚˜ í‚¤ì›Œë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                else:
                    # ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ì €ì¥
                    today = datetime.now().strftime("%Y-%m-%d")
                    current_data = db.read_data()
                    if current_data:
                        if 'collected_news' not in current_data:
                            current_data['collected_news'] = {}
                        current_data['collected_news'][today] = articles
                        current_data['collected_news'][f"{today}_collected_at"] = str(datetime.now())
                        
                        # GitHubì— ì €ì¥
                        if db.write_data(current_data, f"Collect news for {today}"):
                            st.success(f"âœ… {len(articles)}ê°œì˜ ë‰´ìŠ¤ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.info("'ìˆ˜ì§‘ëœ ë‰´ìŠ¤' íƒ­ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                            time.sleep(1)
                            st.rerun()
                        else:
                            st.error("ë‰´ìŠ¤ ì €ì¥ ì‹¤íŒ¨")
                    else:
                        st.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        
        st.divider()
        st.subheader("ğŸ¤– ë¸Œë¦¬í•‘ ìƒì„±")
        today = datetime.now().strftime("%Y-%m-%d")
        
        # ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        collected_news = data.get('collected_news', {})
        date_keys = [k for k in collected_news.keys() if not k.endswith('_collected_at')]
        
        if today in date_keys:
            articles = collected_news[today]
            st.info(f"ğŸ“° ì˜¤ëŠ˜ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(articles)}ê°œ")
            
            if st.button("ë¸Œë¦¬í•‘ ìƒì„± (ì§€ê¸ˆ ì‹¤í–‰)", type="primary"):
                with st.spinner("Gemini AIê°€ ë¸Œë¦¬í•‘ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    # AI ë¶„ì„
                    report_content = analyze_with_gemini(articles)
                    
                    # ê²°ê³¼ ì €ì¥ (ìµœì‹  ë°ì´í„° ë‹¤ì‹œ ì½ê¸°)
                    current_data = db.read_data()
                    if current_data:
                        current_data['reports'][today] = {
                            "content": report_content,
                            "sources": articles,
                            "created_at": str(datetime.now())
                        }
                        
                        # GitHubì— ì €ì¥
                        if db.write_data(current_data, f"New report for {today}"):
                            st.success("ë¸Œë¦¬í•‘ ìƒì„± ì™„ë£Œ!")
                            st.info("'ë°ì¼ë¦¬ ë¸Œë¦¬í•‘' íƒ­ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                            time.sleep(1)
                            st.rerun()
                        else:
                            st.error("ë¸Œë¦¬í•‘ ì €ì¥ ì‹¤íŒ¨")
                    else:
                        st.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        else:
            st.warning("âš ï¸ ë¨¼ì € ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
            st.info("ìœ„ì˜ 'ë‰´ìŠ¤ ìˆ˜ì§‘' ë²„íŠ¼ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        st.divider()
        st.subheader("ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê´€ë¦¬")
        
        # ë‚ ì§œ ì„ íƒ
        collected_news = data.get('collected_news', {})
        date_keys = [k for k in collected_news.keys() if not k.endswith('_collected_at')]
        date_keys = sorted(date_keys, reverse=True)
        
        if date_keys:
            selected_date = st.selectbox("ë‚ ì§œ ì„ íƒ", date_keys, index=0)
            
            if selected_date in collected_news:
                articles = collected_news[selected_date]
                collected_at = collected_news.get(f"{selected_date}_collected_at", "ì•Œ ìˆ˜ ì—†ìŒ")
                st.info(f"ğŸ“° {selected_date}ì— ìˆ˜ì§‘ëœ ë‰´ìŠ¤ {len(articles)}ê°œ")
                st.caption(f"ìˆ˜ì§‘ ì‹œê°„: {collected_at}")
                
                # ê²€ìƒ‰ ê¸°ëŠ¥
                search_term = st.text_input("ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰", key="news_search")
                
                # í•„í„°ë§ëœ ë‰´ìŠ¤
                filtered_articles = articles
                if search_term:
                    filtered_articles = [
                        art for art in articles 
                        if search_term.lower() in art['title'].lower() or 
                           search_term.lower() in art.get('summary', '').lower()
                    ]
                    st.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(filtered_articles)}ê°œ")
                
                # ìƒì„¸ ì •ë³´ í‘œì‹œ
                for idx, art in enumerate(filtered_articles, 1):
                    with st.expander(f"{idx}. {art['title']}", expanded=False):
                        st.write(f"**ë§í¬:** [{art['link']}]({art['link']})")
                        st.write(f"**ë°œí–‰ì¼:** {art['published']}")
                        if art.get('summary'):
                            st.write(f"**ìš”ì•½:** {art['summary']}")
        else:
            st.info("ì•„ì§ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ 'ë‰´ìŠ¤ ìˆ˜ì§‘' ë²„íŠ¼ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")


